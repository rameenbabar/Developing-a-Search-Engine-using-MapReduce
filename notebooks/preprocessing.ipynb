import pandas as pd
import nltk
from nltk.tokenize import word_tokenize
import re

df = pd.read_csv('subset.csv')

def preprocess_text(text):
    text = text.lower()
    text = re.sub(r'[^a-zA-Z\s]', '', text)
    tokens = word_tokenize(text)
    tokens = [token for token in tokens if token.strip()]
    return tokens

df['SECTION_TEXT'] = df['SECTION_TEXT'].apply(lambda x: preprocess_text(x))

#empty dictionary to store unique words and their term frequencies
word_to_index = {}
#calculate term frequency for each word
for idx, tokens_list in enumerate(df['SECTION_TEXT']):
    # Initialize a dictionary to store term frequencies for this section text
    term_frequency = {}
    for word in tokens_list:
        # Increment the term frequency for the word in this section text
        term_frequency[word] = term_frequency.get(word, 0) + 1
        # If the word is not already in word_to_index dictionary, add it with its index
        if word not in word_to_index:
            word_to_index[word] = len(word_to_index)  # Assign a unique index to each unique word

#vocabulary
print("Vocabulary:")
for word, idx in sorted(word_to_index.items(), key=lambda x: x[1]):
    print(idx, word)
print("\n")

for idx, tokens_list in enumerate(df['SECTION_TEXT']):
    # Initialize a dictionary to store term frequencies for this section text
    term_frequency = {}
    for word in tokens_list:
        # Increment the term frequency for the word in this section text
        term_frequency[word] = term_frequency.get(word, 0) + 1

    print(f"Term frequencies for Section {df['ARTICLE_ID'][idx]}:")
    for word, frequency in term_frequency.items():
        print(f"({word_to_index[word]}, {frequency})", end=", ")
    print("\n")
